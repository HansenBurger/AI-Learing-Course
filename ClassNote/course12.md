# OPENCV算法解析

## 一、OPENCV

1. opencv是开源的**计算机视觉库**

2. opencv源码用C和C++编写, 提供了python,JAVA的库

3. 应用广泛, 包含计算机视觉的领域都能用到

4. 查opencv官方手册(因为包含的函数很多), 不需要全部记住, 掌握

**opencv图片读取为BGR**, 而不是RGB

```python
img = cv.
```

特性:
    1. 除读取顺序外, 其他库均为RGB
    2. 除PIL读img类, 其他库读取均为numpy矩阵
    3. 处理性能最好的为opencv

## 二、最小二乘法

### 2.1 线性回归

y=2x: 2(回归系数), 斜率为回归系数

线性回归表示这些离散点**总体上**"**最逼近**"哪条直线

1. 通过**最小化误差的平方和**, 寻找数据的最佳函数匹配(找直线)

2. 最小二乘法可以简便地求得未知数据, 并是的误差平方和最小

3. 残差: $r_i = h(x_i) - y_i$ 其中h(x_i)回归的估计值

4. 三种范数
    1. ∞范数: 残差绝对值的最大值 $max_{1≤i≤m}|r_i|$
    2. 1-范数: 绝对残差和, 所有数据点的残差距离之和
    3. 2-范数: 残差平方和: $sum^m_{i=1}r^2_i$

5. 拟合程度, 拟合函数h(x)与待求解函数y之间的相似性, 2-范数越小,相似性越高

> 使用2-范数的原因, 方便进行微分运算

### 2.2 最小二乘定义

找残差平方和最小的

无约束的最优化问题, 分别对k和b求偏导, 令偏导数为0, 即可获得极值点

求出的直线上并不有点, 但和周围点的距离最短

对于误差相对敏感

## 三、RANSAC

随机采样一致性 (random sample consensus)

### 3.1 定义

1. RANSAC**是一种思想**, 一个求解已知模型的参数框架。**不限定某一特定问题, 可以是计算机是视觉问题，也可以是统计数学甚至经济学领域的模型参数估计问题**

2. 迭代的方法

3. **内群**数据可以通过几组模型参数来叙述数据分布, **离群**数据不适合模型化的数据。给定一组(通常很小)内群, 存在一个程序, 可以估算最佳解释或者适用于这一数据模型的参数。

(其他步骤一致, 什么样的结果还是看传递的参数)

模型已知, 参数待定

相比于最小二乘法**减少噪声点的干扰**

### 3.2 优势

1. 生产实践中的数据往往存在一定的偏差

2. 最小二乘法只适合误差较小的情况

3. 模型确定, 最大迭代次数允许, RANSAC总能找到最优解(80%的误差时), 相对费时

### 3.3 步骤

输入:

1. 一组观测数据(包含较大噪声和无效点)
2. 一个用于解释观测数据的参数化模型(**模型已知**), $y=ax+b$
3. 一些可信参数

步骤:

1. 在数据中随机找几个点设定为内群
2. 计算适合内群的模型 $y=ax+b$ -> 中的a和b (可以是最小二乘法)
3. 把刚才没选到的点带入模型, 计算是否为内群 (带入算出误差, 看是否在阈值内来判断是否是内群)
4. 计算内群数量
5. 重复以上步骤
6. 比较哪次计算中内群数量最多, 内群最多的那次所建模型就是需要的解

注意: **不同问题对应数学模型不同, 因此在计算模型参数时方法必定不同, RANSAC的作用不在于计算模型参数(导致ransac缺点是模型已知)**

问题:
    1. 一开始要随机选择多少点(n)
    2. 要重复几次

> 模型必须已知

### 3.4 参数确定

1. 假设每个点的真正内群概率w: $w = 内群数目/(内群数目+外群数目)$

2. 参数w未知
    1. $w^n$ 表示选择的n个点都是内群的机率
    2. $1-w^n$ 所选择的n个点中至少有一个不是内群的概率
    3. $(1-w^n)^k$ 重复k次都没有全部n为内群的机率
    4. $p = 1 - (1-w^n)^k$ 算法跑了k次后的成功机率

3. 反求: $K = log(1-P)/log(1-w^n)$

4. n--, k↑, p↑; w--, n↑, k↑

5. 通常w未知, n选小一些好

### 3.5 优缺点

优点:
    1. 鲁棒的估计模型参数, 从大量局外点的数据集中估计出高精度的参数

缺点:
    1. 就按参数迭代次数没上限, 上限得到的不一定是最优解
    2. RANSAC只有一定的概率得到可信模型, 迭代次数和概率正比
    3. 要求设置和问题相关的阈值
    4. RANSAC只能从特定数据集中估计一个模型, 存在两个或多个模型, RANSAC不能找到别的模型
    5. 要求数学模型已知

随机的好处找到最优比遍历快

深度学习: 大数据量的检测, 传统方法噪声敏感, 速度慢

## 四、哈希算法

### 4.1 哈希

定义:

1. 从任何一种数据中创建小的数字"指纹"的方法。使得数据量变小, 格式固定
2. 通过哈希一段明文得到哈希值, 哈希值唯一
3. 哈希算法是一个函数, 能把几乎所有的数字文件都转换成一串由数字和字幕构成的看似乱码的字符串

特点:

1. 不可逆性。从输出获得输入很难
2. 输出值唯一性和不可预测性。只要输入信息有一点区别, 哈希输出值也不同。

### 4.2 汉明距离

两个整数之间汉明距离为两个数字对应二进制位不同的位置数目

1: ( 0 0 0 1 )

4: ( 0 1 0 0 )

汉明距离为: 2

### 4.3 均值哈希算法

步骤:

1. 缩放: 图片-> 8*8, 保留结构, 除去细节 (下采样)
2. 灰度化: 转为灰度图 (如果考虑颜色信息则不做灰度化)
3. 求均值: 计算灰度图所有像素的平均值
4. 比较: 像素值大于**平均值**为1, 相反为0, 总共64位
5. 生成hash: 将上述步骤生成1和0按顺序组合起来为图片的指纹(hash)
6. 对比指纹: 计算汉明距离, 不同位数越少越相似

注意: 可能下采样的哈希相同, 但是原图不同(概率相对小), 8*8不同, 哈希也可能一样(因为分析均值)

### 4.4 差值哈希算法

和均值哈希算法前后期基本相同, 只有中间比较变化

步骤:

1. 缩放: 图片-> 8*9, 保留结构, 除去细节 (下采样)
2. 灰度化: 转为灰度图 (如果考虑颜色信息则不做灰度化)
3. 比较: **像素和后一个比**, 大记1, 小记0。不和下一行对比, 每行9个, 8个差值(下采样成8*9原因)
4. 生成hash: 将上述步骤生成1和0按顺序组合起来为图片的指纹(hash)
5. 对比指纹: 计算汉明距离, 不同位数越少越相似

### 4.5 算法比较

aHash: 均值哈希。速度快, 有时不精确。

pHash: 感知哈希。精度高, 速度较差。

dHash: 差值哈希。精度高, 且速度较快。

无法从哈希值返回到缩率图, 返回到明文, 不可逆性

## 五、拓展-DCT

略
